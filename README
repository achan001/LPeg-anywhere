[==[ Albert patches to lpeg 1.0.1 ]==]

Tip: set this file in lua mode !

[=[ P(patt) / -num ]=]

-- -num is treated as -num + (captures + 1), so -1 = last capture
-- can now return result of greedy search, without helper func
-- example: return last word

t = 'this and that and whatever'

=re.match(t, "(g <- {%w+} / .%W* g)+")
this    and     that    and     whatever

=re.match(t, "(g <- {%w+} / .%W* g)+ -> -1")
whatever            -- last capture only

=re.match(t, "(%W* {.%w*})+ -> -1")
whatever            -- more efficient pat

[=[ lpeg.pcode and lpeg.ptree show hex in '\xXX' ]=]

-- so lua understand it, ok to copy/paste
-- speed up string.match with pre-built class (if needed)

=ptree( re.compile "[^%a\x00]" )
[]
set[\x01-\x40\x5b-\x60\x7b-\xff]
=('%q'):format "[\x01-\x40\x5b-\x60\x7b-\xff]"
"[\x01-@[-`{-Â ]"    -- my patched lua to ALWAYS use \xNN

[=[ lpeg.N(patt, [bool = true]) ]=]

-- N(patt) = set of patt non-head-chars

-- for efficient search of patt anywhere forward,
-- we can skip ahead all non-head-chars.
-- After a no-match, we can skip ahead to next possible match:

    skip = P(1) * N(patt)^0

-- N recursive search inside lpeg tree structure for non-head-chars
-- patt = P'hi' + ('Hello' + S'wW' * 'orld') + Cp() * 'HI'
-- N(patt) -> 1 - S'HWhw'

-- Bad cases: for patt w/o head-chars, we wanted a "safe" skip
--> skip = P(1), equate this w/ above:

    N(patt w/o head-chars) = S''

-- Added an optional boolean argument to get head-chars too
-- Note: the goal is for skipping non-head-chars safely, so
-- bad pattern (no head-chars) will return any (thus no skip)

    N(patt, false) = N(patt, nil) = N(N(patt)) -- head-chars
    
-- used bool feature to simplify making class object
--> now Class guaranteed a lpeg set object
--> non-head-chars optimization can be written w/o '>'

    re pattern [[>%pat]] == [[g <- %pat / .[^%pat]* g]]

[=[ lpeg.B(-patt) ]=]

-- lpeg.B(-patt) = behind( fixedlen(patt) )
-- fixedlen = 0 to 255
-- B allow captures (even if not, can rewrite as below)

    B(patt) = B(-patt) * patt

[=[ re.lua ]=]

    %b = lpeg.B(-1), optimize %b^n = Behind n
    '@' = lpeg.B, note : "@!.^n" == "%b^n"
    '>' = lpeg.M searching forward, lpeg.N optimized
    '<' = lpeg.M searching backward, 1 pos at a time    
    '~>' = lpeg.Cf (folding capture)
    
    fix bug: Class to always return lpeg char-set
    fix bug: defined to always return lpeg object
    support for P(patt) / [+-]%d+
    re.split(sep, elem) return lpeg split pattern
    added lpeg.M(pat, skip) for anywhere search (see EXAMPLES)
    added re.def = Predef table, for convenience
    added re.pow(p, n) = p^n w/o the rep code
    
WARNING:
    lpeg think %b is a real char, so watch out for infinite loops
    Example: re.compile "(. %b)*"   -- infinite loop !

[=[ lpeg.B(-patt) effect on capture ]=]

=re.match('123456789', ".. { {...} %b^4 {...} }")
34      345     234
    PATCH: fixedlen(%b)=-1, thus above fixedlen = 2, 3, 3
    2 = 3 - 4 + 3 = -1 + 3 (-1 cannot be used to return variable length)
    fixedlen() return INT32_MIN for variable length

=re.match('123456789', ".. {~ {...} %b^4 {...} ~}")
345234
    PATCH: substcap skip text with len <= 0 (skipped %b^4)
    return "345" .. "234" = "345234"

=re.match('123456789', ".. {%b ...}")
34
    will not capture "234", because substring = "3456789"
    fixedlen = 3-1 = 2, so captured "34"

=re.match('123456789', ".. {@. ..}")
34
    also capture "34", since %b. = @. = lpeg.B(1)
    both pattern are the same, with same pcode

pat = re.compile "{.* (g <- 'and' / %b g)}"

=pat:match(t)       -- greedy search for "(.*and)"
this and that and   -- position after match = 18

=#t:sub(20), #pat:match(t, 20)
7       254
    captured len = 18-20 = -2, (byte) -2 = 0xfe = 254
    254 is wrong, what should it captured ?

=#pat:match(t, 20)  -- after patched lpvm.c match()
0
    should not be nil, because nil = failure
    should not capture anything, beause len = -2
    return "", same behavior as {~ ~}

-- match-time capture:
-- note: added optional defs in re.match for trying things (no memoize)

=re.match(t, "(g <- 'and' / %b g) => print", 17, _G)
this and that and whatever      18      d
nil                 -- captured 'd' = t:sub(17,18-1)

=re.match(t, "(g <- 'and' / %b g) => print", -1, _G)
this and that and whatever      18
nil                 -- 3 returns (not 2), captured ""
    
    PATCH: lpcap.c pushnestedvalues() for implicit capture
    NOTE: =>,~>,-> has VERY HIGH precedence, so ALWAYS use ()

[==[ EXAMPLES ]==]

[=[ re.split(sep, elem) ]=]

go = "1 2 3  123"
=re.match(go, re.split())           -- default: sep=%s, non-empty elem
1       2       3       123
=re.match(go, re.split(nil, ''))    -- empty elem allowed
1       2       3               123
=re.match(go, re.split("[1%s]"))    -- what if 1 also a sep char ?
2       3       23

=re.match(go, re.split(''))         -- empty separtor, split by chars
1               2               3                       1       2       3
=table.concat( re.split(''):Ct():match(go) )
1 2 3  123                          -- split chars to table -> concat

[=[ reversing string ]=]

rev0 = re.compile[[ R <- (!.) -> '' / ({.}R) -> '%2%1' ]]
=rev0:match "123456789" --> 987654321
    this is from lpeg re reference page
    due to recursive calls, this is slow
    possibly overflow backtrack stack for long string

rev1 = re.compile[[ .* {~ (@{.} %b)* ~} ]]
=rev1:match "123456789" --> 987654321
    this pattern is tail recursive and fast
    {~ ~} simply concatenate all captures

[=[ lua pattern "(.*)and(.*)" ]=]

-- this is the pattern that started me patching lpeg
-- it were hard because lpeg greedy match is possessive
-- and if always check 'and' for match, it turned non-greedy
--> trick is to repeat non-greedy matches until no more 'and'

pat1 = re.compile "{(g <- 'and' / .[^a]* g)+ %b^3} .^3 {.*}"
    -- performance is very good (beat string.match w/ long string)
    -- can control which 'and' to get by changing '+'

pat2 = re.compile("{(>%z)+ @!%z} %z {.*}", {z = 'and'})
    -- more general than pat1, no hard-coded %b^3 and .^3
    -- this used my forward match prefix '>'
    -- @!%z undo last captured %z (if %z has fixedlen)
    -- @! read aloud as move backward without matching
    -- performance just as good as pat1

pat3 = re.compile("{>&%z (%z >&%z)*} %z {.*}", {z = 'and'})
    -- I got the idea from string.match frontier pattern
    -- the trick is to set all backtrack mark(s) BEFORE %z
    -- this can handle variable length %z, say %A+
    -- NOTE: ">&'and'" is same as "(g <- &'and' / .[^a]* g)"

pat4 = re.compile("{(. >&%z)*} %z {.*}", {z = 'and'})
    -- pat 2,3 had a hidden bug if z is repeated, say 'andand'
    -- learn about this bug from Roberto peg.pdf, and improved on it
    -- recommend this form unless %z is sured not repeated

pat5 = re.compile "{.* <&'and'} 'and' {.*}"
    -- this used my backward match prefix '<'
    -- true greedy, stop after the "first" 'and'
    -- performance is good, especially if 'and' is close to the end
    -- overall, pat1 is better, with consistent good performance

[=[ regex: Look for a number = "^[+-]?%d+" or "%s[+-]?%d+" ]=]

num1 = re.compile [[ %s* (g <- {[+-]? %d+} / .%S* .%s* g) ]]
    -- both [+-] and %d is subset of %S, so frontier %S work
    -- problem is, there may be many of them

num2 = re.compile [[
    parse  <- number / .%D* search  -- number or skip to %d+
    number <- %s* { [+-]? %d+ }     -- front number
    search <- %b (%s / [+-] %b^2%s) -- validate pattern
              {.%d*}                -- if valid, capture number
    / .%d* .%D* search              -- else, try next %d+
]]
    -- with front number checked, lookbehind will not fail
    -- (adding a space in front of string also work)
    -- go STRAIGHT for the digits, then validate (Python style)
    -- if no digits, will skip the whole line FAST
    -- this is what people do: scan for digits, not spaces !

[=[ efficient search w/ lpeg.M (in re.lua) ]=]

-- 1e6 iterations, time in msec

-- example: search 'whatever'

=timer(1e6, lpeg.match, re.compile[[g <- 'whatever' / .g]], t)
3705    27  -- the safe way
=timer(1e6, lpeg.match, re.compile[[>'whatever']], t)
2454    27  -- more elegant, and faster
=timer(1e6, lpeg.match, lpeg.M'whatever', t)
2454    27  -- same as above

-- example: serach (.... 'ever')

=timer(1e6, lpeg.match, re.compile[[g <- (.... 'ever') / .g]], t)
5608    27  -- skip = P(1)
=timer(1e6, lpeg.match, re.compile[[>(.... 'ever')]], t)
5608    27  -- skip = P(1)*S('')^0 -> optimized to P(1)
=timer(1e6, lpeg.match, M(P(4) * 'ever'), t)
5608    27  -- same as above

-- above naive search does not allow '>' to optimize

=timer(1e6, lpeg.match, re.compile[[>('r' @(.... 'ever'))]], t)
2513    27  -- MUCH better, got a 'r'
=timer(1e6, lpeg.match, M(P'r' * B(P(4) * 'ever')), t)
2513    27  -- same as above

-- lpeg.M really can search anywhere, even backward !
-- lua pattern "(.*)and"

pat = C(P(1)^0 * B(-3) * M(#P'and', B(-1)))

=pat:match(t)
this and that

[=[ faster re.gsub ]=]

-- example: uppercase 't%w+' --> THIS and THAT and whaTEVER
-- To make fair benchmark, we build re.gsub internal pattern
-- also benchmark string.gsub, which is faster for simple pattern

upper = string.upper
pat = re.compile "'t'%w+"
skip = 1 * N(pat)^0

pat_gsub = Cs((pat / upper + 1)^0)
pat_fast = Cs((pat / upper + skip)^0)
pat_M    = Cs(M(pat / upper)^0 * P(1)^0)

=timer(1e6, lpeg.match, pat_gsub, t) --> 9393 ms
=timer(1e6, lpeg.match, pat_M   , t) --> 8862 ms
=timer(1e6, lpeg.match, pat_fast, t) --> 8583 ms
=timer(1e6, string.gsub, t, 't%w+', upper) --> 8272 ms

--> updated re.find to use pat_M optimization (for first match)
--> updated re.gsub to use pat_fast optimization

[=[ controlled gsub ]=]

-- pat_M is slower than pat_fast: it match to end-of-string,
-- THEN backtrack to last match, THEN back to end-of-string AGAIN
-- However, it is more flexible:

=re.match(t, "{~ (>(%pat -> upper))^4 .* ~}", 1, _G)
nil                                 -- 4 replaces failed

=re.match(t, "{~ (>(%pat -> upper))^-2 .* ~}", 1, _G)
THIS and THAT and whatever          -- upto 2 replaces

=re.match(t, "(>{%pat -> upper})^-2", 1, _G)
this    THIS    that    THAT        -- show what got replaced
